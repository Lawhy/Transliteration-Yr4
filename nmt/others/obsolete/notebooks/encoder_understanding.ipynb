{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from nmt.encoder import NMTEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Examine nn.Embedding}:$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a LongTensor A with a shape (3, 4): (batch_size, seq_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 1],\n",
       "        [3, 1, 1, 0],\n",
       "        [3, 2, 0, 0]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(7)\n",
    "A = torch.LongTensor([[1,2,3,1], [3,1,1,0], [3,2,0,0]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7821,  1.0391, -0.7245, -0.8489, -1.2169],\n",
       "         [-0.0810,  1.3615, -2.0615,  0.6741, -1.3233],\n",
       "         [-1.3598, -0.8667, -0.5640, -2.0565, -0.3567],\n",
       "         [ 0.7821,  1.0391, -0.7245, -0.8489, -1.2169]],\n",
       "\n",
       "        [[-1.3598, -0.8667, -0.5640, -2.0565, -0.3567],\n",
       "         [ 0.7821,  1.0391, -0.7245, -0.8489, -1.2169],\n",
       "         [ 0.7821,  1.0391, -0.7245, -0.8489, -1.2169],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-1.3598, -0.8667, -0.5640, -2.0565, -0.3567],\n",
       "         [-0.0810,  1.3615, -2.0615,  0.6741, -1.3233],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(7)\n",
    "em = nn.Embedding(4, 5, padding_idx=0)  #(vocab_size, embedding_size)\n",
    "em(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk/ocean/lhe/conda/envs/pytorch/lib/python3.7/site-packages/torch/nn/modules/rnn.py:51: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7821,  1.0391, -0.7245, -0.8489, -1.2169],\n",
       "         [-0.0810,  1.3615, -2.0615,  0.6741, -1.3233],\n",
       "         [-1.3598, -0.8667, -0.5640, -2.0565, -0.3567],\n",
       "         [ 0.7821,  1.0391, -0.7245, -0.8489, -1.2169]],\n",
       "\n",
       "        [[-1.3598, -0.8667, -0.5640, -2.0565, -0.3567],\n",
       "         [ 0.7821,  1.0391, -0.7245, -0.8489, -1.2169],\n",
       "         [ 0.7821,  1.0391, -0.7245, -0.8489, -1.2169],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-1.3598, -0.8667, -0.5640, -2.0565, -0.3567],\n",
       "         [-0.0810,  1.3615, -2.0615,  0.6741, -1.3233],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(7)\n",
    "test = NMTEncoder(4, 5, 7, 1)\n",
    "test.source_embedding(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 3., 2.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = torch.Tensor([4, 3, 2])\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[ 0.7821,  1.0391, -0.7245, -0.8489, -1.2169],\n",
       "        [-1.3598, -0.8667, -0.5640, -2.0565, -0.3567],\n",
       "        [-1.3598, -0.8667, -0.5640, -2.0565, -0.3567],\n",
       "        [-0.0810,  1.3615, -2.0615,  0.6741, -1.3233],\n",
       "        [ 0.7821,  1.0391, -0.7245, -0.8489, -1.2169],\n",
       "        [-0.0810,  1.3615, -2.0615,  0.6741, -1.3233],\n",
       "        [-1.3598, -0.8667, -0.5640, -2.0565, -0.3567],\n",
       "        [ 0.7821,  1.0391, -0.7245, -0.8489, -1.2169],\n",
       "        [ 0.7821,  1.0391, -0.7245, -0.8489, -1.2169]],\n",
       "       grad_fn=<PackPaddedSequenceBackward>), batch_sizes=tensor([3, 3, 2, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_packed = pack_padded_sequence(test.source_embedding(A), L.detach().cpu().numpy(), \n",
    "                                        batch_first=True)\n",
    "x_packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_birnn_out, x_birnn_h  = test.birnn(x_packed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 14])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_birnn_out.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 14])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[-0.0257,  0.3514, -0.1862,  0.0716, -0.1423, -0.3681, -0.1023, -0.0204,\n",
       "         -0.6083, -0.2706, -0.2377, -0.4160, -0.3308, -0.7484],\n",
       "        [-0.3060, -0.1342,  0.0226, -0.1534,  0.0420, -0.3409, -0.0047,  0.3069,\n",
       "         -0.6709, -0.4534,  0.0832, -0.2172,  0.0017, -0.4740],\n",
       "        [-0.3060, -0.1342,  0.0226, -0.1534,  0.0420, -0.3409, -0.0047, -0.0758,\n",
       "         -0.6710, -0.2347,  0.4194, -0.1586, -0.2441, -0.3111],\n",
       "        [ 0.1014,  0.5060, -0.1416,  0.3485, -0.2273, -0.4966, -0.2600, -0.2441,\n",
       "         -0.7337,  0.1883,  0.2000, -0.2370, -0.4817, -0.5861],\n",
       "        [-0.1428,  0.2943, -0.1686,  0.0132, -0.1000, -0.5351, -0.0853,  0.2300,\n",
       "         -0.5012, -0.3525, -0.3890, -0.5313, -0.1995, -0.6894],\n",
       "        [-0.0278,  0.3530,  0.0063,  0.2001, -0.0558, -0.4587, -0.2121, -0.2664,\n",
       "         -0.5863,  0.2823,  0.1455, -0.3005, -0.4738, -0.3848],\n",
       "        [-0.2679,  0.1561, -0.0934, -0.1150, -0.1729, -0.6172, -0.1933,  0.2854,\n",
       "         -0.6024, -0.4073,  0.1458, -0.1950,  0.0063, -0.3204],\n",
       "        [-0.0827,  0.4723, -0.3154,  0.1116, -0.2272, -0.6654, -0.1218,  0.1844,\n",
       "         -0.3343, -0.2468, -0.2973, -0.4267, -0.1635, -0.4404],\n",
       "        [-0.1303,  0.4127, -0.2643,  0.0518, -0.2694, -0.7116, -0.1506,  0.1844,\n",
       "         -0.3343, -0.2468, -0.2973, -0.4267, -0.1635, -0.4404]],\n",
       "       grad_fn=<CatBackward>), batch_sizes=tensor([3, 3, 2, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_birnn_out.data.shape) # (num_items (非零项), num_rnn * hidden_size)\n",
    "x_birnn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1303,  0.4127, -0.2643,  0.0518, -0.2694, -0.7116, -0.1506],\n",
       "         [-0.0827,  0.4723, -0.3154,  0.1116, -0.2272, -0.6654, -0.1218],\n",
       "         [-0.0278,  0.3530,  0.0063,  0.2001, -0.0558, -0.4587, -0.2121]],\n",
       "\n",
       "        [[-0.0204, -0.6083, -0.2706, -0.2377, -0.4160, -0.3308, -0.7484],\n",
       "         [ 0.3069, -0.6709, -0.4534,  0.0832, -0.2172,  0.0017, -0.4740],\n",
       "         [-0.0758, -0.6710, -0.2347,  0.4194, -0.1586, -0.2441, -0.3111]]],\n",
       "       grad_fn=<PermuteBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_birnn_h = x_birnn_h.permute(1, 0, 2)\n",
    "x_birnn_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 4, 14])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_unpacked, _ = pad_packed_sequence(x_birnn_out, batch_first=True)\n",
    "x_unpacked.shape  # (batch_size, seq_length, num_rnn=2 * hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0257,  0.3514, -0.1862,  0.0716, -0.1423, -0.3681, -0.1023,\n",
       "          -0.0204, -0.6083, -0.2706, -0.2377, -0.4160, -0.3308, -0.7484],\n",
       "         [ 0.1014,  0.5060, -0.1416,  0.3485, -0.2273, -0.4966, -0.2600,\n",
       "          -0.2441, -0.7337,  0.1883,  0.2000, -0.2370, -0.4817, -0.5861],\n",
       "         [-0.2679,  0.1561, -0.0934, -0.1150, -0.1729, -0.6172, -0.1933,\n",
       "           0.2854, -0.6024, -0.4073,  0.1458, -0.1950,  0.0063, -0.3204],\n",
       "         [-0.1303,  0.4127, -0.2643,  0.0518, -0.2694, -0.7116, -0.1506,\n",
       "           0.1844, -0.3343, -0.2468, -0.2973, -0.4267, -0.1635, -0.4404]],\n",
       "\n",
       "        [[-0.3060, -0.1342,  0.0226, -0.1534,  0.0420, -0.3409, -0.0047,\n",
       "           0.3069, -0.6709, -0.4534,  0.0832, -0.2172,  0.0017, -0.4740],\n",
       "         [-0.1428,  0.2943, -0.1686,  0.0132, -0.1000, -0.5351, -0.0853,\n",
       "           0.2300, -0.5012, -0.3525, -0.3890, -0.5313, -0.1995, -0.6894],\n",
       "         [-0.0827,  0.4723, -0.3154,  0.1116, -0.2272, -0.6654, -0.1218,\n",
       "           0.1844, -0.3343, -0.2468, -0.2973, -0.4267, -0.1635, -0.4404],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[-0.3060, -0.1342,  0.0226, -0.1534,  0.0420, -0.3409, -0.0047,\n",
       "          -0.0758, -0.6710, -0.2347,  0.4194, -0.1586, -0.2441, -0.3111],\n",
       "         [-0.0278,  0.3530,  0.0063,  0.2001, -0.0558, -0.4587, -0.2121,\n",
       "          -0.2664, -0.5863,  0.2823,  0.1455, -0.3005, -0.4738, -0.3848],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "           0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],\n",
       "       grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_unpacked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1303,  0.4127, -0.2643,  0.0518, -0.2694, -0.7116, -0.1506, -0.0204,\n",
       "         -0.6083, -0.2706, -0.2377, -0.4160, -0.3308, -0.7484],\n",
       "        [-0.0827,  0.4723, -0.3154,  0.1116, -0.2272, -0.6654, -0.1218,  0.3069,\n",
       "         -0.6709, -0.4534,  0.0832, -0.2172,  0.0017, -0.4740],\n",
       "        [-0.0278,  0.3530,  0.0063,  0.2001, -0.0558, -0.4587, -0.2121, -0.0758,\n",
       "         -0.6710, -0.2347,  0.4194, -0.1586, -0.2441, -0.3111]],\n",
       "       grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_birnn_h.contiguous().view(x_birnn_h.size(0), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that x_birnn_h is equal to concat each last $\\textbf{non-trivial}$ state of x_unpacked!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0257,  0.3514, -0.1862,  0.0716, -0.1423, -0.3681, -0.1023,\n",
       "           -0.0204, -0.6083, -0.2706, -0.2377, -0.4160, -0.3308, -0.7484],\n",
       "          [ 0.1014,  0.5060, -0.1416,  0.3485, -0.2273, -0.4966, -0.2600,\n",
       "           -0.2441, -0.7337,  0.1883,  0.2000, -0.2370, -0.4817, -0.5861],\n",
       "          [-0.2679,  0.1561, -0.0934, -0.1150, -0.1729, -0.6172, -0.1933,\n",
       "            0.2854, -0.6024, -0.4073,  0.1458, -0.1950,  0.0063, -0.3204],\n",
       "          [-0.1303,  0.4127, -0.2643,  0.0518, -0.2694, -0.7116, -0.1506,\n",
       "            0.1844, -0.3343, -0.2468, -0.2973, -0.4267, -0.1635, -0.4404]],\n",
       " \n",
       "         [[-0.3060, -0.1342,  0.0226, -0.1534,  0.0420, -0.3409, -0.0047,\n",
       "            0.3069, -0.6709, -0.4534,  0.0832, -0.2172,  0.0017, -0.4740],\n",
       "          [-0.1428,  0.2943, -0.1686,  0.0132, -0.1000, -0.5351, -0.0853,\n",
       "            0.2300, -0.5012, -0.3525, -0.3890, -0.5313, -0.1995, -0.6894],\n",
       "          [-0.0827,  0.4723, -0.3154,  0.1116, -0.2272, -0.6654, -0.1218,\n",
       "            0.1844, -0.3343, -0.2468, -0.2973, -0.4267, -0.1635, -0.4404],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
       " \n",
       "         [[-0.3060, -0.1342,  0.0226, -0.1534,  0.0420, -0.3409, -0.0047,\n",
       "           -0.0758, -0.6710, -0.2347,  0.4194, -0.1586, -0.2441, -0.3111],\n",
       "          [-0.0278,  0.3530,  0.0063,  0.2001, -0.0558, -0.4587, -0.2121,\n",
       "           -0.2664, -0.5863,  0.2823,  0.1455, -0.3005, -0.4738, -0.3848],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "          [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
       "            0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]],\n",
       "        grad_fn=<TransposeBackward0>),\n",
       " tensor([[-0.1303,  0.4127, -0.2643,  0.0518, -0.2694, -0.7116, -0.1506, -0.0204,\n",
       "          -0.6083, -0.2706, -0.2377, -0.4160, -0.3308, -0.7484],\n",
       "         [-0.0827,  0.4723, -0.3154,  0.1116, -0.2272, -0.6654, -0.1218,  0.3069,\n",
       "          -0.6709, -0.4534,  0.0832, -0.2172,  0.0017, -0.4740],\n",
       "         [-0.0278,  0.3530,  0.0063,  0.2001, -0.0558, -0.4587, -0.2121, -0.0758,\n",
       "          -0.6710, -0.2347,  0.4194, -0.1586, -0.2441, -0.3111]],\n",
       "        grad_fn=<ViewBackward>))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.forward(A, L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
