Params #: 19728323
# multi-task 0.8 0.2
Seq2Seq(
  (encoder): Encoder(
    (embedding): Sequential(
      (0): Embedding(30, 256)
      (1): Dropout(p=0.1, inplace=False)
    )
    (rnn): LSTM(256, 512, num_layers=2, dropout=0.2, bidirectional=True)
  )
  (decoder): Decoder(
    (attention): Attention(
      (attn): Linear(in_features=1536, out_features=512, bias=True)
      (v): Linear(in_features=512, out_features=1, bias=False)
      (linear_out): Linear(in_features=1024, out_features=512, bias=True)
    )
    (embedding): Sequential(
      (0): Embedding(437, 256)
      (1): Dropout(p=0.1, inplace=False)
    )
    (rnn): LSTM(768, 512, num_layers=2, dropout=0.2)
    (pred): Sequential(
      (0): Linear(in_features=1280, out_features=437, bias=True)
      (1): LogSoftmax()
    )
  )
  (decoder_pinyin): Decoder(
    (attention): Attention(
      (attn): Linear(in_features=1280, out_features=256, bias=True)
      (v): Linear(in_features=256, out_features=1, bias=False)
      (linear_out): Linear(in_features=1024, out_features=256, bias=True)
    )
    (embedding): Sequential(
      (0): Embedding(270, 128)
      (1): Dropout(p=0.1, inplace=False)
    )
    (rnn): LSTM(384, 256, num_layers=2, dropout=0.2)
    (pred): Sequential(
      (0): Linear(in_features=640, out_features=270, bias=True)
      (1): LogSoftmax()
    )
  )
  (bridge): Linear(in_features=1024, out_features=512, bias=True)
  (bridge_cell): Linear(in_features=1024, out_features=512, bias=True)
  (bridge_pinyin): Linear(in_features=1024, out_features=256, bias=True)
  (bridge_cell_pinyin): Linear(in_features=1024, out_features=256, bias=True)
)